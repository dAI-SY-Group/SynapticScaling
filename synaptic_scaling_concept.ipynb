{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "batch_size_train = 100\n",
    "batch_size_test = 100\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.fc0 = nn.Linear(784,1024)\n",
    "        self.fc1 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1,784))\n",
    "        x = F.relu(self.fc0(x))\n",
    "        return self.fc1(x)\n",
    "\n",
    "model = mlp().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_param(parameter_data, activation, gamma=0.1,mean = 0.1):\n",
    "    activation = activation.data.numpy().mean(axis=(0)).squeeze()[:,None]\n",
    "    param = parameter_data.numpy()\n",
    "    new_param = param+gamma*np.clip((param*param)*(mean - activation).mean(),-1,1)\n",
    "    return torch.from_numpy(new_param)\n",
    "def perform_update(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.eval()\n",
    "        im = np.random.uniform(-1, 1, (100, m.in_features))+0.1\n",
    "        im_as_ten = torch.from_numpy(im).float().cuda()\n",
    "        x = Variable(im_as_ten, requires_grad=True)\n",
    "        x = F.relu(m(x))\n",
    "        m.weight.data = update_param(m.weight.data.cpu(),activation=x.cpu()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('mnist', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('mnist', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(100 + 1)]\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data=data.cuda()\n",
    "        target=target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target) + 1.0 * (0.1 - output.mean())**2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "    model.apply(perform_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "        return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3196, Accuracy: 768/10000 (8%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.320545\n",
      "\n",
      "Test set: Avg. loss: 0.1113, Accuracy: 9669/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.055593\n",
      "\n",
      "Test set: Avg. loss: 0.0784, Accuracy: 9756/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.035090\n",
      "\n",
      "Test set: Avg. loss: 0.0653, Accuracy: 9807/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.017559\n",
      "\n",
      "Test set: Avg. loss: 0.0602, Accuracy: 9815/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.029249\n",
      "\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 9818/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.045290\n",
      "\n",
      "Test set: Avg. loss: 0.0609, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.007181\n",
      "\n",
      "Test set: Avg. loss: 0.0602, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.016152\n",
      "\n",
      "Test set: Avg. loss: 0.0592, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.015310\n",
      "\n",
      "Test set: Avg. loss: 0.0588, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.009839\n",
      "\n",
      "Test set: Avg. loss: 0.0673, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.014760\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.003572\n",
      "\n",
      "Test set: Avg. loss: 0.0662, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.032251\n",
      "\n",
      "Test set: Avg. loss: 0.0590, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.007223\n",
      "\n",
      "Test set: Avg. loss: 0.0613, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.005457\n",
      "\n",
      "Test set: Avg. loss: 0.0614, Accuracy: 9837/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.032140\n",
      "\n",
      "Test set: Avg. loss: 0.0944, Accuracy: 9752/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.009012\n",
      "\n",
      "Test set: Avg. loss: 0.0722, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.017796\n",
      "\n",
      "Test set: Avg. loss: 0.0586, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.011323\n",
      "\n",
      "Test set: Avg. loss: 0.0578, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.009969\n",
      "\n",
      "Test set: Avg. loss: 0.0600, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.003789\n",
      "\n",
      "Test set: Avg. loss: 0.0568, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.002206\n",
      "\n",
      "Test set: Avg. loss: 0.0567, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.015790\n",
      "\n",
      "Test set: Avg. loss: 0.0537, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.004303\n",
      "\n",
      "Test set: Avg. loss: 0.0580, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.020329\n",
      "\n",
      "Test set: Avg. loss: 0.0724, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.024309\n",
      "\n",
      "Test set: Avg. loss: 0.0673, Accuracy: 9834/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.009258\n",
      "\n",
      "Test set: Avg. loss: 0.0570, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.014018\n",
      "\n",
      "Test set: Avg. loss: 0.0572, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.012328\n",
      "\n",
      "Test set: Avg. loss: 0.0551, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.013717\n",
      "\n",
      "Test set: Avg. loss: 0.0542, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.006816\n",
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.019338\n",
      "\n",
      "Test set: Avg. loss: 0.0543, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.011024\n",
      "\n",
      "Test set: Avg. loss: 0.0524, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.007455\n",
      "\n",
      "Test set: Avg. loss: 0.0656, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.020430\n",
      "\n",
      "Test set: Avg. loss: 0.0560, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.015172\n",
      "\n",
      "Test set: Avg. loss: 0.0548, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.011974\n",
      "\n",
      "Test set: Avg. loss: 0.0532, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.024779\n",
      "\n",
      "Test set: Avg. loss: 0.0540, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.021824\n",
      "\n",
      "Test set: Avg. loss: 0.0534, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.012274\n",
      "\n",
      "Test set: Avg. loss: 0.0538, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.014925\n",
      "\n",
      "Test set: Avg. loss: 0.0531, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.016378\n",
      "\n",
      "Test set: Avg. loss: 0.0516, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.011104\n",
      "\n",
      "Test set: Avg. loss: 0.0530, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.009160\n",
      "\n",
      "Test set: Avg. loss: 0.0685, Accuracy: 9833/10000 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.016752\n",
      "\n",
      "Test set: Avg. loss: 0.0682, Accuracy: 9839/10000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.020866\n",
      "\n",
      "Test set: Avg. loss: 0.0586, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.015549\n",
      "\n",
      "Test set: Avg. loss: 0.0578, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.021173\n",
      "\n",
      "Test set: Avg. loss: 0.0560, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.020083\n",
      "\n",
      "Test set: Avg. loss: 0.0545, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.018350\n",
      "\n",
      "Test set: Avg. loss: 0.0563, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.012280\n",
      "\n",
      "Test set: Avg. loss: 0.0532, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.005674\n",
      "\n",
      "Test set: Avg. loss: 0.0565, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.009563\n",
      "\n",
      "Test set: Avg. loss: 0.0543, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.018297\n",
      "\n",
      "Test set: Avg. loss: 0.0537, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.014468\n",
      "\n",
      "Test set: Avg. loss: 0.0907, Accuracy: 9810/10000 (98%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.032702\n",
      "\n",
      "Test set: Avg. loss: 0.0778, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.035514\n",
      "\n",
      "Test set: Avg. loss: 0.0626, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.021204\n",
      "\n",
      "Test set: Avg. loss: 0.0595, Accuracy: 9867/10000 (99%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.025992\n",
      "\n",
      "Test set: Avg. loss: 0.0588, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.020071\n",
      "\n",
      "Test set: Avg. loss: 0.0591, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.025889\n",
      "\n",
      "Test set: Avg. loss: 0.0585, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.023777\n",
      "\n",
      "Test set: Avg. loss: 0.0574, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.018111\n",
      "\n",
      "Test set: Avg. loss: 0.0562, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.020085\n",
      "\n",
      "Test set: Avg. loss: 0.0570, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.020513\n",
      "\n",
      "Test set: Avg. loss: 0.0571, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.019022\n",
      "\n",
      "Test set: Avg. loss: 0.0573, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.023637\n",
      "\n",
      "Test set: Avg. loss: 0.0825, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.051565\n",
      "\n",
      "Test set: Avg. loss: 0.0784, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.055009\n",
      "\n",
      "Test set: Avg. loss: 0.0720, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.054377\n",
      "\n",
      "Test set: Avg. loss: 0.0693, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.032352\n",
      "\n",
      "Test set: Avg. loss: 0.0691, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.032563\n",
      "\n",
      "Test set: Avg. loss: 0.0685, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.047952\n",
      "\n",
      "Test set: Avg. loss: 0.0672, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.045359\n",
      "\n",
      "Test set: Avg. loss: 0.0677, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.039065\n",
      "\n",
      "Test set: Avg. loss: 0.0684, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.039422\n",
      "\n",
      "Test set: Avg. loss: 0.0920, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.121666\n",
      "\n",
      "Test set: Avg. loss: 0.0833, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.048532\n",
      "\n",
      "Test set: Avg. loss: 0.0706, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.080300\n",
      "\n",
      "Test set: Avg. loss: 0.0712, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.098644\n",
      "\n",
      "Test set: Avg. loss: 0.0715, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.072202\n",
      "\n",
      "Test set: Avg. loss: 0.0736, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.063553\n",
      "\n",
      "Test set: Avg. loss: 0.0742, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.090127\n",
      "\n",
      "Test set: Avg. loss: 0.0756, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.108366\n",
      "\n",
      "Test set: Avg. loss: 0.0897, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.077221\n",
      "\n",
      "Test set: Avg. loss: 0.0998, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.144085\n",
      "\n",
      "Test set: Avg. loss: 0.0875, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.122798\n",
      "\n",
      "Test set: Avg. loss: 0.0922, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.144470\n",
      "\n",
      "Test set: Avg. loss: 0.0927, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.199583\n",
      "\n",
      "Test set: Avg. loss: 0.0938, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.132939\n",
      "\n",
      "Test set: Avg. loss: 0.0960, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.211207\n",
      "\n",
      "Test set: Avg. loss: 0.1278, Accuracy: 9813/10000 (98%)\n",
      "\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.238408\n",
      "\n",
      "Test set: Avg. loss: 0.1082, Accuracy: 9823/10000 (98%)\n",
      "\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.291456\n",
      "\n",
      "Test set: Avg. loss: 0.1084, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.135681\n",
      "\n",
      "Test set: Avg. loss: 0.1215, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.327335\n",
      "\n",
      "Test set: Avg. loss: 0.1131, Accuracy: 9817/10000 (98%)\n",
      "\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.266927\n",
      "\n",
      "Test set: Avg. loss: 0.1249, Accuracy: 9811/10000 (98%)\n",
      "\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.484175\n",
      "\n",
      "Test set: Avg. loss: 0.1414, Accuracy: 9805/10000 (98%)\n",
      "\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.525668\n",
      "\n",
      "Test set: Avg. loss: 0.1515, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.562668\n",
      "\n",
      "Test set: Avg. loss: 0.1406, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.373488\n",
      "\n",
      "Test set: Avg. loss: 0.1359, Accuracy: 9803/10000 (98%)\n",
      "\n",
      "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.563414\n",
      "\n",
      "Test set: Avg. loss: 0.1400, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.559591\n",
      "\n",
      "Test set: Avg. loss: 0.1430, Accuracy: 9795/10000 (98%)\n",
      "\n",
      "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.588774\n",
      "\n",
      "Test set: Avg. loss: 0.1649, Accuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.770250\n",
      "\n",
      "Test set: Avg. loss: 0.1703, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 105 [0/60000 (0%)]\tLoss: 0.989364\n",
      "\n",
      "Test set: Avg. loss: 0.1851, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Train Epoch: 106 [0/60000 (0%)]\tLoss: 0.835074\n",
      "\n",
      "Test set: Avg. loss: 0.1868, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 107 [0/60000 (0%)]\tLoss: 1.354493\n",
      "\n",
      "Test set: Avg. loss: 0.1987, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 108 [0/60000 (0%)]\tLoss: 1.151566\n"
     ]
    },
   ],
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
